{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "151a7a29",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ab29d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import json\n",
    "import time\n",
    "from PIL import Image\n",
    "import io\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386506a7",
   "metadata": {},
   "source": [
    "# Extract web content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb55524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request was successful.\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.tilbudsugen.dk/partner/netto-114?page=100'\n",
    "\n",
    "response = requests.get(url)\n",
    "time.sleep(2)\n",
    "if response.status_code == 200:\n",
    "    print(\"Request was successful.\")\n",
    "else:\n",
    "    assert False, f\"Request failed with status code {response.status_code}\"\n",
    "\n",
    "soup = bs4.BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579abfd8",
   "metadata": {},
   "source": [
    "# Get product ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e775aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = soup.find_all('a', href=True)\n",
    "product_links = [link['href'] for link in links if link['href'].startswith('https://www.tilbudsugen.dk/single/')]\n",
    "all_ids = [int(link.split('/')[-1]) for link in product_links]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb79d025",
   "metadata": {},
   "source": [
    "# Get product info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b3d4abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing #0 of 477\n",
      "Processing #10 of 477\n",
      "Processing #20 of 477\n",
      "Processing #30 of 477\n",
      "Processing #40 of 477\n",
      "Processing #50 of 477\n",
      "Processing #60 of 477\n",
      "Processing #70 of 477\n",
      "Processing #80 of 477\n",
      "Processing #90 of 477\n",
      "Processing #100 of 477\n",
      "Processing #110 of 477\n",
      "Processing #120 of 477\n",
      "Processing #130 of 477\n",
      "Processing #140 of 477\n",
      "Processing #150 of 477\n",
      "Processing #160 of 477\n",
      "Processing #170 of 477\n",
      "Processing #180 of 477\n",
      "Processing #190 of 477\n",
      "Processing #200 of 477\n",
      "Processing #210 of 477\n",
      "Processing #220 of 477\n",
      "Processing #230 of 477\n",
      "Processing #240 of 477\n",
      "Processing #250 of 477\n",
      "Processing #260 of 477\n",
      "Processing #270 of 477\n",
      "Processing #280 of 477\n",
      "Processing #290 of 477\n",
      "Processing #300 of 477\n",
      "Processing #310 of 477\n",
      "Processing #320 of 477\n",
      "Processing #330 of 477\n",
      "Processing #340 of 477\n",
      "Processing #350 of 477\n",
      "Processing #360 of 477\n",
      "Processing #370 of 477\n",
      "Processing #380 of 477\n",
      "Processing #390 of 477\n",
      "Processing #400 of 477\n",
      "Processing #410 of 477\n",
      "Processing #420 of 477\n",
      "Processing #430 of 477\n",
      "Processing #440 of 477\n",
      "Processing #450 of 477\n",
      "Processing #460 of 477\n",
      "Processing #470 of 477\n"
     ]
    }
   ],
   "source": [
    "products = {}\n",
    "all_ids = all_ids\n",
    "N = len(all_ids)\n",
    "for i, data_id in enumerate(all_ids):\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Processing #{i} of {N}\")\n",
    "    data_url = f\"https://www.tilbudsugen.dk/_next/data/0LbXUdvz48Lb0tgkd4pVT/dk/single/{data_id}.json?id={data_id}\"\n",
    "    response = requests.get(data_url)\n",
    "    time.sleep(1)\n",
    "    if response.status_code != 200:\n",
    "        assert False, f\"Request failed with status code {response.status_code}\"\n",
    "    page_props = response.json()['pageProps']\n",
    "    # print(json.dumps(page_props, indent=2))\n",
    "    \n",
    "    price        = page_props['offer']['price']\n",
    "    brand        = page_props['offer']['brand']['name']\n",
    "    category     = page_props['offer']['productVariant']['category']['name']\n",
    "    product_name = page_props['offer']['productName']['productName']\n",
    "    units        = page_props['offer']['units']\n",
    "    quantity     = int(eval(page_props['offer']['quantity']))\n",
    "    unit_type    = page_props['offer']['unitType']\n",
    "    store_name   = page_props['offer']['chain']['name']\n",
    "    image_url    = page_props['offer']['imageUrl']\n",
    "    start_date   = page_props['offer']['startDate']\n",
    "    end_date     = page_props['offer']['endDate']\n",
    "\n",
    "    products[data_id] = [price, brand, category, product_name, units, quantity, unit_type, store_name, image_url, start_date, end_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fe4fc6",
   "metadata": {},
   "source": [
    "# Gather data in table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d5e4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products = pd.DataFrame.from_dict(products, orient='index', columns=['price', 'brand', 'category', 'product_name', 'units', 'quantity', 'unit_type', 'store_name', 'image_url', 'start_date', 'end_date'])\n",
    "df_products.reset_index(inplace=True)\n",
    "df_products.rename(columns={'index': 'data_id'}, inplace=True)\n",
    "date = df_products['start_date'].mode()[0]\n",
    "df_products.to_csv(f'../data/csv/products_{date}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adf2e8",
   "metadata": {},
   "source": [
    "# Download resized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76f330d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_resize_image(image_url, data_id, date):\n",
    "    extension = image_url.split(\"?\")[0].split(\".\")[-1].lower()\n",
    "    os.makedirs(f\"../data/imgs/{date}\", exist_ok=True)\n",
    "    filename = f\"../data/imgs/{date}/{data_id}.{extension}\"\n",
    "\n",
    "    resp = requests.get(image_url)\n",
    "    if resp.status_code != 200:\n",
    "        print(\"Failed to download image:\", resp.status_code)\n",
    "    else:\n",
    "        img = Image.open(io.BytesIO(resp.content))\n",
    "        w, h = img.size\n",
    "        max_side = max(w, h)\n",
    "        if max_side > 300:\n",
    "            scale = 300 / max_side\n",
    "            new_size = (int(round(w * scale)), int(round(h * scale)))\n",
    "            try:\n",
    "                resample = Image.Resampling.LANCZOS\n",
    "            except AttributeError:\n",
    "                resample = Image.LANCZOS\n",
    "            img = img.resize(new_size, resample)\n",
    "        img.save(filename)\n",
    "\n",
    "# for all product_ids in df_products, download and resize images\n",
    "for idx, row in df_products.iterrows():\n",
    "    download_and_resize_image(row['image_url'], row['data_id'], date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d7421c",
   "metadata": {},
   "source": [
    "# Cloudinary image hosting service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36149ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cloudinary in /home/mp/anaconda3/lib/python3.9/site-packages (1.44.1)\n",
      "Requirement already satisfied: certifi in /home/mp/anaconda3/lib/python3.9/site-packages (from cloudinary) (2022.9.14)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /home/mp/anaconda3/lib/python3.9/site-packages (from cloudinary) (1.26.11)\n",
      "Requirement already satisfied: six in /home/mp/anaconda3/lib/python3.9/site-packages (from cloudinary) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install cloudinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fccf9824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudinary\n",
    "import cloudinary.uploader\n",
    "from cloudinary.utils import cloudinary_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5da0085d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cloudinary.Config at 0x729480cb0940>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration       \n",
    "\n",
    "API_SECRET = os.getenv(\"CLOUDINARY_KEY\")\n",
    "\n",
    "cloudinary.config( \n",
    "    cloud_name = \"dfqzmnlga\", \n",
    "    api_key    = \"733583949868714\", \n",
    "    api_secret = API_SECRET,\n",
    "    secure=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "778db4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://res.cloudinary.com/dfqzmnlga/image/upload/v1761556503/shoes.jpg\n"
     ]
    }
   ],
   "source": [
    "# Upload an image\n",
    "upload_result = cloudinary.uploader.upload(\"https://res.cloudinary.com/demo/image/upload/getting-started/shoes.jpg\", public_id=\"shoes\")\n",
    "print(upload_result[\"secure_url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d47c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://res.cloudinary.com/dfqzmnlga/image/upload/v1761557466/2025-10-25/10738668.jpg\n"
     ]
    }
   ],
   "source": [
    "# Upload an image\n",
    "upload_result = cloudinary.uploader.upload(\"../data/imgs/2025-10-25/10738668.jpg\", public_id=f\"10738668\", asset_folder=date)\n",
    "print(upload_result[\"secure_url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57e40665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 13.9326171875 KB\n"
     ]
    }
   ],
   "source": [
    "# print size of image in bytes (folder = data/imgs/2025-10-25/10738667.jpg)\n",
    "import os\n",
    "file_path = \"../data/imgs/2025-10-25/10738667.jpg\"\n",
    "file_size = os.path.getsize(file_path)\n",
    "print(f\"File size: {file_size / 1024} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba914799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total folder size: 7.014111518859863 MB\n"
     ]
    }
   ],
   "source": [
    "# print size of entire folder\n",
    "import os\n",
    "folder_path = \"../data/imgs/2025-10-25/\"\n",
    "total_size = 0\n",
    "for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "    for f in filenames:\n",
    "        fp = os.path.join(dirpath, f)\n",
    "        total_size += os.path.getsize(fp)\n",
    "print(f\"Total folder size: {total_size / (1024 * 1024)} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
