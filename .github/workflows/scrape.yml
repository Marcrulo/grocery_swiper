name: Weekly scraping

on:
  schedule:
    # run weekly saturday at midnight
    - cron: '0 0 * * 6'
  workflow_dispatch: # allows manual run

jobs:
  run-python:
    runs-on: ubuntu-latest

    permissions:
      contents: write

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
      with:
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12.11'

    - name: Install dependencies 
      run: |
        ls -l
        python -m pip install --upgrade pip
        if [ -f requirements_scrape.txt ]; then pip install -r requirements_scrape.txt; fi
    - name: Run Python scripts
      env:
        CLOUDINARY_KEY: ${{ secrets.CLOUDINARY_KEY }}
      run: |
        cd scripts
        python scrape.py
    - name: Push output file to branch
      run: |
        git config --global user.name "github-actions[bot]"
        git config --global user.email "github-actions[bot]@users.noreply.github.com"
        git add . data/csv/
        git commit -m "Update output for $(date +'%Y-%m-%d')"
        git push -u origin master --force